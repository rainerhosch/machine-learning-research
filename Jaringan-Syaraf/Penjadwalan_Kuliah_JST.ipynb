{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP5XWXBCURpr1W5W9m3k3qm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rainerhosch/machine-learning-research/blob/main/Jaringan-Syaraf/Penjadwalan_Kuliah_JST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "he2SnRgPjgBN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.preprocessing import LabelEncoder\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Parameter Dataset\n",
        "num_courses = 100  # Jumlah mata kuliah\n",
        "num_lecturers = 20  # Jumlah dosen\n",
        "num_time_slots = 10  # Jumlah slot waktu\n",
        "num_rooms = 5  # Jumlah ruangan\n",
        "\n",
        "# 2. Generate Data\n",
        "np.random.seed(42)  # Untuk hasil yang konsisten\n",
        "data = {\n",
        "    \"Course_Code\": [f\"C{str(i).zfill(3)}\" for i in range(num_courses)],\n",
        "    \"Lecturer_ID\": np.random.choice(range(1, num_lecturers + 1), num_courses),\n",
        "    \"Time_Slot\": np.random.choice(range(1, num_time_slots + 1), num_courses),\n",
        "    \"Room_ID\": np.random.choice(range(1, num_rooms + 1), num_courses),\n",
        "}\n",
        "\n",
        "# 3. Buat DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# 4. Simpan ke CSV\n",
        "df.to_csv('schedule_data.csv', index=False)\n",
        "\n",
        "print(\"Dataset Dummy berhasil dibuat!\")\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HM5UeRgTkvKZ",
        "outputId": "27a2d266-7bf3-4334-95d5-ace1c1d8d78f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Dummy berhasil dibuat!\n",
            "  Course_Code  Lecturer_ID  Time_Slot  Room_ID\n",
            "0        C000            7          3        4\n",
            "1        C001           20          8        3\n",
            "2        C002           15          6        4\n",
            "3        C003           11          3        3\n",
            "4        C004            8          1        2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Load data\n",
        "dataset = pd.read_csv(\"/content/data_jadwal_kuliah.csv\")\n",
        "\n",
        "# Encode categorical data\n",
        "encoder_waktu = LabelEncoder()\n",
        "encoder_ruangan = LabelEncoder()\n",
        "dataset['Slot_Waktu'] = encoder_waktu.fit_transform(dataset['Slot_Waktu'])\n",
        "dataset['Ruangan'] = encoder_ruangan.fit_transform(dataset['Ruangan'])\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "X = dataset[['Kode_Mk', 'Id_Dosen']].copy()\n",
        "X['Kode_Mk'] = LabelEncoder().fit_transform(X['Kode_Mk'])\n",
        "y = dataset[['Slot_Hari', 'Slot_Waktu', 'Ruangan']]\n",
        "\n",
        "# Split and scale data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Define ANN model\n",
        "model = Sequential([\n",
        "    Dense(64, input_dim=X_train.shape[1], activation='relu'),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(y_train.shape[1], activation='linear')\n",
        "])\n",
        "\n",
        "# Compile and train the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=16, validation_split=0.2, verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, mae = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test Loss: {loss}, Test MAE: {mae}\")\n",
        "\n",
        "# Save the model\n",
        "model.save(\"jadwal_model.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQ4-9Aiojz5i",
        "outputId": "83a89e44-cf9e-41af-e18a-ac3d80022f95"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - loss: 202.9933 - mae: 10.8320 - val_loss: 168.5055 - val_mae: 9.5741\n",
            "Epoch 2/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 181.2672 - mae: 9.9415 - val_loss: 126.7921 - val_mae: 8.0308\n",
            "Epoch 3/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 121.7309 - mae: 7.7526 - val_loss: 74.4467 - val_mae: 6.4250\n",
            "Epoch 4/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 72.9282 - mae: 6.1734 - val_loss: 67.4529 - val_mae: 6.0958\n",
            "Epoch 5/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 68.0709 - mae: 6.0499 - val_loss: 61.4467 - val_mae: 5.9367\n",
            "Epoch 6/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 63.4750 - mae: 5.8082 - val_loss: 60.5999 - val_mae: 5.9169\n",
            "Epoch 7/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 62.9979 - mae: 5.8558 - val_loss: 60.1181 - val_mae: 5.8743\n",
            "Epoch 8/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 63.8016 - mae: 5.8630 - val_loss: 59.3226 - val_mae: 5.8376\n",
            "Epoch 9/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 59.8164 - mae: 5.7854 - val_loss: 58.7552 - val_mae: 5.7876\n",
            "Epoch 10/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 57.9136 - mae: 5.6325 - val_loss: 58.3517 - val_mae: 5.7634\n",
            "Epoch 11/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 58.2469 - mae: 5.6796 - val_loss: 57.7978 - val_mae: 5.7334\n",
            "Epoch 12/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 62.0756 - mae: 5.8821 - val_loss: 57.4321 - val_mae: 5.7038\n",
            "Epoch 13/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 60.6216 - mae: 5.8722 - val_loss: 56.8189 - val_mae: 5.6744\n",
            "Epoch 14/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 61.6674 - mae: 5.9446 - val_loss: 57.7346 - val_mae: 5.6933\n",
            "Epoch 15/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 56.9929 - mae: 5.7262 - val_loss: 56.7734 - val_mae: 5.6603\n",
            "Epoch 16/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 56.3843 - mae: 5.6982 - val_loss: 55.8668 - val_mae: 5.5954\n",
            "Epoch 17/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 55.8787 - mae: 5.6087 - val_loss: 56.8585 - val_mae: 5.6765\n",
            "Epoch 18/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 57.4701 - mae: 5.7669 - val_loss: 55.5219 - val_mae: 5.5861\n",
            "Epoch 19/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 56.5135 - mae: 5.6737 - val_loss: 55.6964 - val_mae: 5.6019\n",
            "Epoch 20/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 54.7480 - mae: 5.6305 - val_loss: 55.0828 - val_mae: 5.5820\n",
            "Epoch 21/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 55.2551 - mae: 5.6998 - val_loss: 55.3656 - val_mae: 5.5804\n",
            "Epoch 22/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 54.5651 - mae: 5.6007 - val_loss: 54.9807 - val_mae: 5.5673\n",
            "Epoch 23/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 54.0660 - mae: 5.6156 - val_loss: 54.4702 - val_mae: 5.5367\n",
            "Epoch 24/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 53.6765 - mae: 5.6028 - val_loss: 54.9197 - val_mae: 5.5816\n",
            "Epoch 25/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 53.7297 - mae: 5.5789 - val_loss: 54.3555 - val_mae: 5.5234\n",
            "Epoch 26/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 55.3827 - mae: 5.7079 - val_loss: 54.9085 - val_mae: 5.5621\n",
            "Epoch 27/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 51.4855 - mae: 5.5161 - val_loss: 54.5166 - val_mae: 5.5387\n",
            "Epoch 28/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 50.5538 - mae: 5.4389 - val_loss: 54.5646 - val_mae: 5.5292\n",
            "Epoch 29/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 50.8840 - mae: 5.4340 - val_loss: 53.8310 - val_mae: 5.5041\n",
            "Epoch 30/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 52.3909 - mae: 5.5975 - val_loss: 54.2451 - val_mae: 5.5372\n",
            "Epoch 31/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 49.6935 - mae: 5.3551 - val_loss: 54.3082 - val_mae: 5.5276\n",
            "Epoch 32/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 49.7934 - mae: 5.3501 - val_loss: 54.2504 - val_mae: 5.5197\n",
            "Epoch 33/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 48.8859 - mae: 5.3811 - val_loss: 54.3436 - val_mae: 5.5321\n",
            "Epoch 34/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 48.6324 - mae: 5.3116 - val_loss: 54.0092 - val_mae: 5.5127\n",
            "Epoch 35/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 49.6169 - mae: 5.3731 - val_loss: 54.7283 - val_mae: 5.5855\n",
            "Epoch 36/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 48.9719 - mae: 5.3793 - val_loss: 54.6957 - val_mae: 5.5666\n",
            "Epoch 37/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 48.0263 - mae: 5.3724 - val_loss: 53.9068 - val_mae: 5.5204\n",
            "Epoch 38/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 48.6848 - mae: 5.3844 - val_loss: 54.1858 - val_mae: 5.5378\n",
            "Epoch 39/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 48.5025 - mae: 5.3249 - val_loss: 54.1351 - val_mae: 5.5295\n",
            "Epoch 40/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 46.7507 - mae: 5.2614 - val_loss: 54.0976 - val_mae: 5.5425\n",
            "Epoch 41/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 48.0505 - mae: 5.3384 - val_loss: 54.0918 - val_mae: 5.5222\n",
            "Epoch 42/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 48.5798 - mae: 5.3981 - val_loss: 53.4490 - val_mae: 5.4872\n",
            "Epoch 43/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 49.4548 - mae: 5.3965 - val_loss: 53.5725 - val_mae: 5.4805\n",
            "Epoch 44/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 47.5586 - mae: 5.3278 - val_loss: 53.9450 - val_mae: 5.5329\n",
            "Epoch 45/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 49.4801 - mae: 5.4438 - val_loss: 53.7025 - val_mae: 5.5214\n",
            "Epoch 46/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 48.6803 - mae: 5.4246 - val_loss: 53.5934 - val_mae: 5.4913\n",
            "Epoch 47/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 43.7181 - mae: 5.0784 - val_loss: 54.5093 - val_mae: 5.5476\n",
            "Epoch 48/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 45.8032 - mae: 5.1939 - val_loss: 53.7150 - val_mae: 5.5107\n",
            "Epoch 49/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 45.1414 - mae: 5.1880 - val_loss: 53.3215 - val_mae: 5.4932\n",
            "Epoch 50/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 48.1562 - mae: 5.3631 - val_loss: 55.2233 - val_mae: 5.5783\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 53.228816986083984, Test MAE: 5.581546783447266\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the trained model\n",
        "model = load_model(\"jadwal_model.h5\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egsIbibGyDWe",
        "outputId": "a3013ec2-e4f9-4fac-f9f6-2fe3ceade97d"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load new data\n",
        "new_data = pd.DataFrame({\n",
        "    'Kode_Mk': ['TT19111', 'DK19131'],  # contoh data\n",
        "    'Id_Dosen': [147, 42]\n",
        "})\n",
        "\n",
        "# Encode and scale new data\n",
        "new_data['Kode_Mk'] = LabelEncoder().fit_transform(new_data['Kode_Mk'])  # Gunakan encoder lama\n",
        "new_data_scaled = scaler.transform(new_data)\n"
      ],
      "metadata": {
        "id": "j7oGbMR-yKQo"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict schedule for new data\n",
        "predictions = model.predict(new_data_scaled)\n",
        "\n",
        "# Decode predictions\n",
        "decoded_predictions = {\n",
        "    'Slot_Hari': predictions[:, 0].round().astype(int),\n",
        "    'Slot_Waktu': encoder_waktu.inverse_transform(predictions[:, 1].round().astype(int)),\n",
        "    'Ruangan': encoder_ruangan.inverse_transform(predictions[:, 2].round().astype(int))\n",
        "}\n",
        "\n",
        "result = pd.DataFrame(decoded_predictions)\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ALhl4-n_9KS",
        "outputId": "47a8ee41-77f4-4cb5-e0ec-23cecf8836b6"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x78f343eb0c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316ms/step\n",
            "   Slot_Hari   Slot_Waktu Ruangan\n",
            "0          3  12:30-14:10      17\n",
            "1          4  18:00-19:40      32\n"
          ]
        }
      ]
    }
  ]
}